{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-24T16:12:05.648490Z",
     "start_time": "2020-07-24T16:12:01.927726Z"
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-24T16:16:26.997291Z",
     "start_time": "2020-07-24T16:16:26.932372Z"
    }
   },
   "outputs": [],
   "source": [
    "seed = 23455\n",
    "\n",
    "rdm = np.random.RandomState(seed=seed)\n",
    "x = rdm.rand(32,2)\n",
    "y_ = [[x1+x2+(rdm.rand()/10.0-0.05)] for (x1,x2) in x]\n",
    "x = tf.cast(x,dtype=tf.float32)\n",
    "\n",
    "w1 = tf.Variable(tf.random.normal([2,1],stddev=1,seed=1))\n",
    "\n",
    "epoch = 15000\n",
    "lr = 0.002"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-24T16:20:43.602055Z",
     "start_time": "2020-07-24T16:20:32.782438Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After 0 training steps w1 is \n",
      "[[-0.8096241]\n",
      " [ 1.4855157]] \n",
      "\n",
      "After 500 training steps w1 is \n",
      "[[-0.21934733]\n",
      " [ 1.6984866 ]] \n",
      "\n",
      "After 1000 training steps w1 is \n",
      "[[0.0893971]\n",
      " [1.673225 ]] \n",
      "\n",
      "After 1500 training steps w1 is \n",
      "[[0.28368822]\n",
      " [1.5853055 ]] \n",
      "\n",
      "After 2000 training steps w1 is \n",
      "[[0.423243 ]\n",
      " [1.4906037]] \n",
      "\n",
      "After 2500 training steps w1 is \n",
      "[[0.531055 ]\n",
      " [1.4053345]] \n",
      "\n",
      "After 3000 training steps w1 is \n",
      "[[0.61725086]\n",
      " [1.332841  ]] \n",
      "\n",
      "After 3500 training steps w1 is \n",
      "[[0.687201 ]\n",
      " [1.2725208]] \n",
      "\n",
      "After 4000 training steps w1 is \n",
      "[[0.7443262]\n",
      " [1.2227542]] \n",
      "\n",
      "After 4500 training steps w1 is \n",
      "[[0.7910986]\n",
      " [1.1818361]] \n",
      "\n",
      "After 5000 training steps w1 is \n",
      "[[0.82943517]\n",
      " [1.1482395 ]] \n",
      "\n",
      "After 5500 training steps w1 is \n",
      "[[0.860872 ]\n",
      " [1.1206709]] \n",
      "\n",
      "After 6000 training steps w1 is \n",
      "[[0.88665503]\n",
      " [1.098054  ]] \n",
      "\n",
      "After 6500 training steps w1 is \n",
      "[[0.90780276]\n",
      " [1.0795006 ]] \n",
      "\n",
      "After 7000 training steps w1 is \n",
      "[[0.92514884]\n",
      " [1.0642821 ]] \n",
      "\n",
      "After 7500 training steps w1 is \n",
      "[[0.93937725]\n",
      " [1.0517985 ]] \n",
      "\n",
      "After 8000 training steps w1 is \n",
      "[[0.951048]\n",
      " [1.041559]] \n",
      "\n",
      "After 8500 training steps w1 is \n",
      "[[0.96062106]\n",
      " [1.0331597 ]] \n",
      "\n",
      "After 9000 training steps w1 is \n",
      "[[0.9684733]\n",
      " [1.0262702]] \n",
      "\n",
      "After 9500 training steps w1 is \n",
      "[[0.97491425]\n",
      " [1.0206193 ]] \n",
      "\n",
      "After 10000 training steps w1 is \n",
      "[[0.9801975]\n",
      " [1.0159837]] \n",
      "\n",
      "After 10500 training steps w1 is \n",
      "[[0.9845312]\n",
      " [1.0121814]] \n",
      "\n",
      "After 11000 training steps w1 is \n",
      "[[0.9880858]\n",
      " [1.0090628]] \n",
      "\n",
      "After 11500 training steps w1 is \n",
      "[[0.99100184]\n",
      " [1.0065047 ]] \n",
      "\n",
      "After 12000 training steps w1 is \n",
      "[[0.9933934]\n",
      " [1.0044063]] \n",
      "\n",
      "After 12500 training steps w1 is \n",
      "[[0.9953551]\n",
      " [1.0026854]] \n",
      "\n",
      "After 13000 training steps w1 is \n",
      "[[0.99696386]\n",
      " [1.0012728 ]] \n",
      "\n",
      "After 13500 training steps w1 is \n",
      "[[0.9982835]\n",
      " [1.0001147]] \n",
      "\n",
      "After 14000 training steps w1 is \n",
      "[[0.9993659]\n",
      " [0.999166 ]] \n",
      "\n",
      "After 14500 training steps w1 is \n",
      "[[1.0002553 ]\n",
      " [0.99838644]] \n",
      "\n",
      "Final w1 is : [[1.0009792]\n",
      " [0.9977485]]\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(epoch):\n",
    "    with tf.GradientTape() as tape:\n",
    "        y = tf.matmul(x,w1)\n",
    "        loss_mes = tf.reduce_mean(tf.square(y_-y))\n",
    "    grads = tape.gradient(loss_mes,w1)\n",
    "    w1.assign_sub(lr*grads)\n",
    "    \n",
    "    if epoch % 500 ==0 :\n",
    "        print(\"After %d training steps w1 is \"% (epoch))\n",
    "        print(w1.numpy(),\"\\n\")\n",
    "print(\"Final w1 is :\", w1.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-24T16:27:18.486769Z",
     "start_time": "2020-07-24T16:27:00.108123Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After 0 training steps w1 is \n",
      "[[2.8579698]\n",
      " [2.8479836]] \n",
      "\n",
      "After 500 training steps w1 is \n",
      "[[1.1466794]\n",
      " [1.0426497]] \n",
      "\n",
      "After 1000 training steps w1 is \n",
      "[[1.1370593]\n",
      " [1.0739335]] \n",
      "\n",
      "After 1500 training steps w1 is \n",
      "[[1.1274396]\n",
      " [1.1052176]] \n",
      "\n",
      "After 2000 training steps w1 is \n",
      "[[1.1178197]\n",
      " [1.1365014]] \n",
      "\n",
      "After 2500 training steps w1 is \n",
      "[[1.1668332]\n",
      " [1.1790786]] \n",
      "\n",
      "After 3000 training steps w1 is \n",
      "[[1.1363947]\n",
      " [1.0338919]] \n",
      "\n",
      "After 3500 training steps w1 is \n",
      "[[1.1267751]\n",
      " [1.0651761]] \n",
      "\n",
      "After 4000 training steps w1 is \n",
      "[[1.1171551]\n",
      " [1.0964599]] \n",
      "\n",
      "After 4500 training steps w1 is \n",
      "[[1.1661687]\n",
      " [1.1390371]] \n",
      "\n",
      "After 5000 training steps w1 is \n",
      "[[1.1565483]\n",
      " [1.1703205]] \n",
      "\n",
      "After 5500 training steps w1 is \n",
      "[[1.1261101]\n",
      " [1.0251341]] \n",
      "\n",
      "After 6000 training steps w1 is \n",
      "[[1.1164902]\n",
      " [1.0564181]] \n",
      "\n",
      "After 6500 training steps w1 is \n",
      "[[1.1068704]\n",
      " [1.087702 ]] \n",
      "\n",
      "After 7000 training steps w1 is \n",
      "[[1.1558837]\n",
      " [1.130279 ]] \n",
      "\n",
      "After 7500 training steps w1 is \n",
      "[[1.146264]\n",
      " [1.161563]] \n",
      "\n",
      "After 8000 training steps w1 is \n",
      "[[1.1158255]\n",
      " [1.0163764]] \n",
      "\n",
      "After 8500 training steps w1 is \n",
      "[[1.1648387]\n",
      " [1.0589532]] \n",
      "\n",
      "After 9000 training steps w1 is \n",
      "[[1.1552186]\n",
      " [1.0902369]] \n",
      "\n",
      "After 9500 training steps w1 is \n",
      "[[1.1455989]\n",
      " [1.121521 ]] \n",
      "\n",
      "After 10000 training steps w1 is \n",
      "[[1.1359786]\n",
      " [1.1528045]] \n",
      "\n",
      "After 10500 training steps w1 is \n",
      "[[1.1849921]\n",
      " [1.1953816]] \n",
      "\n",
      "After 11000 training steps w1 is \n",
      "[[1.1545538]\n",
      " [1.0501951]] \n",
      "\n",
      "After 11500 training steps w1 is \n",
      "[[1.1449339]\n",
      " [1.0814791]] \n",
      "\n",
      "After 12000 training steps w1 is \n",
      "[[1.1353139]\n",
      " [1.1127628]] \n",
      "\n",
      "After 12500 training steps w1 is \n",
      "[[1.1843275]\n",
      " [1.1553401]] \n",
      "\n",
      "After 13000 training steps w1 is \n",
      "[[1.1538888]\n",
      " [1.0101532]] \n",
      "\n",
      "After 13500 training steps w1 is \n",
      "[[1.1442686]\n",
      " [1.0414368]] \n",
      "\n",
      "After 14000 training steps w1 is \n",
      "[[1.1346488]\n",
      " [1.0727208]] \n",
      "\n",
      "After 14500 training steps w1 is \n",
      "[[1.1250292]\n",
      " [1.104005 ]] \n",
      "\n",
      "Final w1 is : [[1.1278243]\n",
      " [1.0271062]]\n"
     ]
    }
   ],
   "source": [
    "cost = 1\n",
    "profit = 99\n",
    "\n",
    "\n",
    "for epoch in range(epoch):\n",
    "    with tf.GradientTape() as tape:\n",
    "        y = tf.matmul(x,w1)\n",
    "        loss = tf.reduce_sum(tf.where(tf.greater(y,y_),(y-y_)*cost,(y_-y)*profit))\n",
    "    grads = tape.gradient(loss,w1)\n",
    "    w1.assign_sub(lr*grads)\n",
    "    \n",
    "    if epoch % 500 ==0 :\n",
    "        print(\"After %d training steps w1 is \"% (epoch))\n",
    "        print(w1.numpy(),\"\\n\")\n",
    "print(\"Final w1 is :\", w1.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6.9 64-bit",
   "language": "python",
   "name": "python36964bit7e091a4bc7ad4c03b45358b2d91294f7"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
